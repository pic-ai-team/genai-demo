{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --quiet newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始文章: 網紅「晚安小雞」傳出遭柬埔寨警方逮捕，網友懷疑知情的涉案人更多。另一名直播主「倫家會怕」今天凌晨發文澄清，他當初極力阻止「晚安小雞」去柬埔寨，「但他們確實欺騙了我跟大家，我被蒙在鼓裡也是非常的氣憤」。\n",
      "\n",
      "晚安小雞在柬埔寨拍片遭指控造假，風波愈演愈烈。柬中時報報導，柬埔寨警方指控晚安小雞涉嫌自導自演、故意損害柬埔寨形象聲譽，警方今天下午將召開記者會說明，而警方公布的照片中出現兩人，包括晚安小雞和阿鬧。\n",
      "\n",
      "網紅「四叉貓」在臉書點名目前登場人物累計5人，包括晚安小雞夫妻、阿鬧、廠商、靈異探險直播主「倫家會怕」。\n",
      "\n",
      "四叉貓表示，「倫家會怕」過去常在晚安小雞直播出現，昨天被流出疑似說溜嘴、知道柬埔寨事件是自導自演的一小段影片，不過今天清晨2點發文自稱被騙。\n",
      "\n",
      "「倫家會怕」的聲明文表示，他前還是沒辦法聯繫上小雞與阿鬧，看新聞得知是被柬埔寨當局扣押，「說實在我也是非常驚訝與錯愕，與我知道的相差甚遠」，原本以為只有小雞自己前往柬埔寨探險。\n",
      "\n",
      "「倫家會怕」表示，他原本極力阻止小雞隻身前往，認為太危險，「但小雞跟我說他想給哥姐們看見不一樣的世界，讓大家看到世界不一樣的角落，還開玩笑的與我說或許能救一些人回來」。並指小雞正向又熱血，這也是他追隨的原因。「但他們確實欺騙了我跟大家，我被蒙在鼓裡也是非常的氣憤，怎麼做壞事也沒有找我？」\n",
      "\n",
      "「倫家會怕」表示，他相信小雞現在也是非常的懊悔，但人都要為自己的選擇負責，他希望可以給小雞、阿鬧一個機會，一起祈求他們可以平安歸來，靜待司法部門調查。「我也將休息一陣子等待他們的歸來，沒有任何的切割，偶代表：倫家會怕粉絲專頁，偶會陪伴晚安小雞渡過所有難關」。\n",
      "============================================================\n",
      "總結文章: 網紅「晚安小雞」在柬埔寨被捕，涉嫌自導自演損害其形象。警方公布的照片顯示其男友「阿鬧」也涉案。直播主「倫家會怕」聲稱自己也被騙，並極力阻止過「晚安小雞」前往。目前已確認涉案人員累計5人，事件仍在調查中。\n"
     ]
    }
   ],
   "source": [
    "import newspaper\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "\n",
    "\n",
    "# 爬網頁內容\n",
    "url = r\"https://udn.com/news/story/7321/7769693\"\n",
    "article = newspaper.Article(url=url)\n",
    "article.download()\n",
    "article.parse()\n",
    "print(f\"原始文章: {article.text}\")\n",
    "print(\"============================================================\")\n",
    "\n",
    "# 生成總結\n",
    "prompt = \"\"\"請簡潔的總結下列文章:\n",
    "{content}\n",
    "簡潔的總結:\"\"\"\n",
    "\n",
    "vertexai.init(project=\"pic-hr-aitraining\", location=\"asia-southeast1\")\n",
    "model = GenerativeModel(\"gemini-pro\")\n",
    "responses = model.generate_content(\n",
    "  prompt.format(content=article.text),\n",
    "  generation_config={\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"temperature\": 0.9,\n",
    "      \"top_p\": 1\n",
    "  }\n",
    ")\n",
    "print(f\"總結文章: {responses.candidates[0].text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
