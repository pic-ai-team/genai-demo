{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Detection\n",
    "The goal of this notebook is to detect what a passage is talking about using an LLM. Each user needs to be authenticated individually in order to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Input, authentication, and evaluation flow](./vertex_flow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-aiplatform in /home/lumor/.local/lib/python3.9/site-packages (1.42.0)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /home/lumor/.local/lib/python3.9/site-packages (from google-cloud-aiplatform) (2.0.2)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (2.14.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (2.27.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (2.16.2)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (23.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (3.17.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /home/lumor/.local/lib/python3.9/site-packages (from google-cloud-aiplatform) (1.12.1)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from google-cloud-aiplatform) (4.23.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.60.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.60.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.9/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.9/dist-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.9/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-16 10:22:14.727660: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-16 10:22:14.784562: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-16 10:22:14.784611: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-16 10:22:14.786497: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-16 10:22:14.796395: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-16 10:22:14.798035: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-16 10:22:16.078916: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "import vertexai.preview.generative_models as generative_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login \n",
    "# !gcloud auth application-default set-quota-project pic-semantic-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "VertexAI requires authentication before querying the model. For this notebook, test accounts will be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Change the authentication\n",
    "configs = {\"project\": \"pic-gen-ai-project\",\n",
    "            \"region\": \"asia-northeast1\"}\n",
    "vertexai.init(\n",
    "    project=configs[\"project\"],\n",
    "    location=configs[\"region\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt:str, model:GenerativeModel):\n",
    "  \"\"\"Pass a prompt to the generative model, print the response.\"\"\"\n",
    "  responses = model.generate_content(\n",
    "    prompt,\n",
    "    generation_config={\n",
    "        \"max_output_tokens\": 2048,\n",
    "        \"temperature\": 0.9,\n",
    "        \"top_p\": 1\n",
    "    },\n",
    "    safety_settings={\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "          generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    },\n",
    "    stream=True,\n",
    "  )\n",
    "  \n",
    "  for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing samples\n",
    "Our simple dataset is focused on sentences from various topics ranging from news to enterntainment. We wish our model to infer the sentence topic and simply return the topic being discussed. The `generate()` function takes in the prompt with the target sentence and queries the model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UK economy slips into recession\n",
      "United Kingdom's economy\n",
      "\n",
      "Here's Why It Might Seem Like You've Gained Weight In Your Face\n",
      "Facial weight gain\n",
      "\n",
      "The quick brown fox jumps over the lazy dog.\n",
      "English alphabet\n",
      "\n",
      "S&P 500 sets new record as it hits 5000.\n",
      "Stock market\n",
      "\n",
      "Five recipes to start off the Chiense New Year.\n",
      "Chinese New Year cooking\n",
      "\n",
      "Germany overtakes Japan as world's third largest economy.\n",
      "Economy\n",
      "\n",
      "The 2022 world cup final drew more than 1.5 billion viewers\n",
      "FIFA World Cup\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PROMPT = \"Given a sentence or a short passage, identify the topic being discussed and return your guess as a single word or phrase. Sentence: \"\n",
    "\n",
    "# These topics are mostly from news headlines. Requests are normally limited to 10 per minute\n",
    "dataset = [\"UK economy slips into recession\",\n",
    "           \"Here's Why It Might Seem Like You've Gained Weight In Your Face\",\n",
    "           \"The quick brown fox jumps over the lazy dog.\",\n",
    "           \"S&P 500 sets new record as it hits 5000.\",\n",
    "           \"Five recipes to start off the Chiense New Year.\",\n",
    "           \"Germany overtakes Japan as world's third largest economy.\",\n",
    "           \"The 2022 world cup final drew more than 1.5 billion viewers\"\n",
    "        ]\n",
    "\n",
    "# These include excerpts from the news articles, are still summarized in a few lines.\n",
    "longer_dataset = [\"The Insatiable Ambition of LeBron James: The basketball legend is building a business that includes movies and TV, advertising and a grooming line. It’s all part of a new model for how athletes can cash in on their fame.\",\n",
    "                \"Part of an ancient fossil prized for what its mummified flesh revealed about a reptile that predated the first dinosaurs has been shown to be a forgery. While the fossil’s legs and scales are genuine, portions of what appeared to be an intact 8-inch-long reptile are painted rock.\",\n",
    "                \"OpenAI has introduced new technology that uses artificial intelligence to create high-quality videos from text descriptions. The company released short clips showcasing vivid, seemingly realistic videos, including woolly mammoths trekking across a snowy field, ocean waves crashing against a cliff’s shoreline and people doing everyday things like reading a book or walking down a city street. OpenAI calls the new system Sora. It takes a written prompt and, through AI, renders a richly detailed video. OpenAI is one of many companies like Alphabet’s Google and Meta Platforms seeking to capitalize on new AI-video developments.\",\n",
    "]\n",
    "\n",
    "# Create an instance of a gemini-pro model in our project\n",
    "model = GenerativeModel(\"gemini-1.0-pro\")\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "    generate(PROMPT + item, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
